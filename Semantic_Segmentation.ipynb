{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVS934qbHur0",
        "outputId": "b86018b7-e2cc-4236-b9a8-6e345e4f0447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "3FTrryZlYNo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import csv\n"
      ],
      "metadata": {
        "id": "-n3FhCCCX49O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "I9ib7wMlYDRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using CPU"
      ],
      "metadata": {
        "id": "AQ2LdmI7mVZB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnbrFPzQXX3w"
      },
      "outputs": [],
      "source": [
        "# Define paths to dataset directories\n",
        "data_dir = '/content/drive/MyDrive/CamVid'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_labels_dir = os.path.join(data_dir, 'train_labels')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "val_labels_dir = os.path.join(data_dir, 'val_labels')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "test_labels_dir = os.path.join(data_dir, 'test_labels')\n",
        "class_dict_file = os.path.join(data_dir, 'class_dict.csv')\n",
        "\n",
        "# Function to load class dictionary from CSV\n",
        "def load_class_dict(csv_file):\n",
        "    class_dict = {}\n",
        "    with open(csv_file, mode='r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            class_name = row['name']\n",
        "            rgb = (int(row['r']), int(row['g']), int(row['b']))\n",
        "            class_dict[class_name] = rgb\n",
        "    return class_dict\n",
        "\n",
        "# Function to load and preprocess images and labels\n",
        "def load_data(image_paths, label_paths, class_dict, width, height):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img_path, lbl_path in zip(image_paths, label_paths):\n",
        "        img = img_to_array(load_img(img_path, target_size=(width, height)))  # Resize to specified dimensions\n",
        "        lbl = img_to_array(load_img(lbl_path, target_size=(width, height), color_mode='rgb')) / 255.0\n",
        "        lbl = convert_to_categorical(lbl, class_dict)\n",
        "        images.append(img)\n",
        "        labels.append(lbl)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Function to convert label image to categorical labels\n",
        "def convert_to_categorical(label_image, class_dict):\n",
        "    categorical_labels = np.zeros(label_image.shape[:2], dtype=np.uint8)\n",
        "    for class_name, rgb in class_dict.items():\n",
        "        mask = np.all(label_image == rgb, axis=-1)\n",
        "        categorical_labels[mask] = list(class_dict.keys()).index(class_name)\n",
        "    return categorical_labels\n",
        "\n",
        "# Load class dictionary from CSV file\n",
        "class_dict = load_class_dict(class_dict_file)\n",
        "\n",
        "# Define image dimensions\n",
        "width = 960\n",
        "height = 720\n",
        "\n",
        "# Load train, validation, and test data\n",
        "train_images, train_labels = load_data(\n",
        "    [os.path.join(train_dir, filename) for filename in os.listdir(train_dir)],\n",
        "    [os.path.join(train_labels_dir, filename) for filename in os.listdir(train_labels_dir)],\n",
        "    class_dict,\n",
        "    width,\n",
        "    height\n",
        ")\n",
        "val_images, val_labels = load_data(\n",
        "    [os.path.join(val_dir, filename) for filename in os.listdir(val_dir)],\n",
        "    [os.path.join(val_labels_dir, filename) for filename in os.listdir(val_labels_dir)],\n",
        "    class_dict,\n",
        "    width,\n",
        "    height\n",
        ")\n",
        "test_images, test_labels = load_data(\n",
        "    [os.path.join(test_dir, filename) for filename in os.listdir(test_dir)],\n",
        "    [os.path.join(test_labels_dir, filename) for filename in os.listdir(test_labels_dir)],\n",
        "    class_dict,\n",
        "    width,\n",
        "    height\n",
        ")\n",
        "\n",
        "# Normalize pixel values of images\n",
        "train_images = train_images / 255.0\n",
        "val_images = val_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using GPU"
      ],
      "metadata": {
        "id": "kAo4vVUTmO2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to dataset directories\n",
        "data_dir = '/content/drive/MyDrive/CamVid'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_labels_dir = os.path.join(data_dir, 'train_labels')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "val_labels_dir = os.path.join(data_dir, 'val_labels')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "test_labels_dir = os.path.join(data_dir, 'test_labels')\n",
        "class_dict_file = os.path.join(data_dir, 'class_dict.csv')\n",
        "\n",
        "# Function to load class dictionary from CSV\n",
        "def load_class_dict(csv_file):\n",
        "    class_dict = {}\n",
        "    with open(csv_file, mode='r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            class_name = row['name']\n",
        "            rgb = (int(row['r']), int(row['g']), int(row['b']))\n",
        "            class_dict[class_name] = rgb\n",
        "    return class_dict\n",
        "\n",
        "# Function to load and preprocess images and labels\n",
        "def load_data(image_paths, label_paths, class_dict, width, height):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img_path, lbl_path in zip(image_paths, label_paths):\n",
        "        img = tf.io.read_file(img_path)\n",
        "        img = tf.image.decode_png(img, channels=3)  # Assume PNG images with 3 channels\n",
        "        img = tf.image.resize(img, (width, height))\n",
        "        img = img / 255.0\n",
        "\n",
        "        lbl = tf.io.read_file(lbl_path)\n",
        "        lbl = tf.image.decode_png(lbl, channels=3)  # Assume PNG label images with 3 channels\n",
        "        lbl = tf.image.resize(lbl, (width, height))\n",
        "        lbl = img_to_array(lbl) / 255.0\n",
        "        lbl = convert_to_categorical(lbl, class_dict)\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(lbl)\n",
        "    return tf.stack(images), tf.stack(labels)\n",
        "\n",
        "# Function to convert label image to categorical labels\n",
        "def convert_to_categorical(label_image, class_dict):\n",
        "    categorical_labels = np.zeros(label_image.shape[:2], dtype=np.uint8)\n",
        "    for class_name, rgb in class_dict.items():\n",
        "        mask = tf.reduce_all(tf.equal(label_image, rgb), axis=-1)\n",
        "        categorical_labels[mask] = list(class_dict.keys()).index(class_name)\n",
        "    return categorical_labels\n",
        "\n",
        "# Load class dictionary from CSV file\n",
        "class_dict = load_class_dict(class_dict_file)\n",
        "\n",
        "# Define image dimensions\n",
        "width = 960\n",
        "height = 720\n",
        "\n",
        "# Load train, validation, and test data\n",
        "train_images, train_labels = load_data(\n",
        "    [os.path.join(train_dir, filename) for filename in os.listdir(train_dir)],\n",
        "    [os.path.join(train_labels_dir, filename) for filename in os.listdir(train_labels_dir)],\n",
        "    class_dict,\n",
        "    width,\n",
        "    height\n",
        ")\n",
        "val_images, val_labels = load_data(\n",
        "    [os.path.join(val_dir, filename) for filename in os.listdir(val_dir)],\n",
        "    [os.path.join(val_labels_dir, filename) for filename in os.listdir(val_labels_dir)],\n",
        "    class_dict,\n",
        "    width,\n",
        "    height\n",
        ")\n",
        "test_images, test_labels = load_data(\n",
        "    [os.path.join(test_dir, filename) for filename in os.listdir(test_dir)],\n",
        "    [os.path.join(test_labels_dir, filename) for filename in os.listdir(test_labels_dir)],\n",
        "    class_dict,\n",
        "    width,\n",
        "    height\n",
        ")\n",
        "\n",
        "# Print shapes of loaded data\n",
        "print(\"Train Images Shape:\", train_images.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Validation Images Shape:\", val_images.shape)\n",
        "print(\"Validation Labels Shape:\", val_labels.shape)\n",
        "print(\"Test Images Shape:\", test_images.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n"
      ],
      "metadata": {
        "id": "SaZAMrRNjjOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5be5429-2b6b-4407-ef9d-4789eb58d056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images Shape: (369, 960, 720, 3)\n",
            "Train Labels Shape: (369, 960, 720)\n",
            "Validation Images Shape: (100, 960, 720, 3)\n",
            "Validation Labels Shape: (100, 960, 720)\n",
            "Test Images Shape: (232, 960, 720, 3)\n",
            "Test Labels Shape: (232, 960, 720)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resizing the Images (Optional)**"
      ],
      "metadata": {
        "id": "nFR3s_0NtNUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.image import resize\n",
        "\n",
        "# Resize images to a smaller resolution\n",
        "resized_train_images = resize(train_images, (480, 360))\n",
        "resized_val_images = resize(val_images, (480, 360))\n",
        "resized_test_images = resize(test_images, (480, 360))"
      ],
      "metadata": {
        "id": "672l4c5OmJ8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation"
      ],
      "metadata": {
        "id": "jguh07XCYKMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set TensorFlow to use GPU memory dynamically\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n"
      ],
      "metadata": {
        "id": "WuykZRVviPsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738ca4fa-f204-4ebd-8220-558f8fc3d22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Physical devices cannot be modified after being initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "\n",
        "def unet(input_shape, num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Contracting Path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    # Bottom\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    # Expansive Path\n",
        "    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n",
        "    merge6 = concatenate([drop4, up6], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = concatenate([conv3, up7], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = concatenate([conv2, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = concatenate([conv1, up9], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (960, 720, 3)  # Assuming images are 720x960 RGB\n",
        "num_classes = len(class_dict)  # Number of classes from the class dictionary\n",
        "\n",
        "# Create U-Net model\n",
        "model = unet(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "9L38CNh3YMNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "3M7xn5MDFUrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define batch size and number of epochs\n",
        "batch_size = 2\n",
        "epochs = 10\n",
        "\n",
        "# Define the file path where checkpoints will be saved\n",
        "checkpoint_path = \"/content/drive/MyDrive/model_checkpoint.h5\"\n",
        "\n",
        "# Create a ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                      save_weights_only=True,\n",
        "                                      monitor='val_loss',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)\n",
        "\n",
        "# Train the model using the checkpoint callback\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(val_images, val_labels),\n",
        "                    callbacks=[checkpoint_callback])\n",
        "\n",
        "# After training, you can load the best model weights from the checkpoint file\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Define the file path where the model will be saved\n",
        "model_path = \"/content/drive/MyDrive/segmentation_model.h5\"\n",
        "\n",
        "# Save the entire model\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "4BUzBlQV9pUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "tsCmpGVHFf86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def convert_to_segmented_images(predictions, class_dict):\n",
        "    num_samples, height, width = predictions.shape\n",
        "    num_classes = len(class_dict)\n",
        "    segmented_images = np.zeros((num_samples, height, width, 3), dtype=np.uint8)\n",
        "\n",
        "    # Convert each pixel to RGB color based on class dictionary\n",
        "    for i in range(num_samples):\n",
        "        for h in range(height):\n",
        "            for w in range(width):\n",
        "                class_index = predictions[i, h, w]\n",
        "                class_label = class_dict[class_index]\n",
        "                # Assign RGB color based on class label (assuming class_dict contains RGB values)\n",
        "                segmented_images[i, h, w] = class_label\n",
        "\n",
        "    return segmented_images\n",
        "\n",
        "# Make predictions on the test set\n",
        "predicted_labels = model.predict(test_images)\n",
        "\n",
        "# Convert predicted labels to segmented images\n",
        "segmented_images = convert_to_segmented_images(predicted_labels)  # You need to implement this function\n",
        "\n",
        "# Visualize original and segmented images\n",
        "n = min(len(test_images), 5)  # Display up to 5 images\n",
        "plt.figure(figsize=(10, 4*n))\n",
        "for i in range(n):\n",
        "    plt.subplot(n, 2, 2*i + 1)\n",
        "    plt.imshow(test_images[i])\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(n, 2, 2*i + 2)\n",
        "    plt.imshow(segmented_images[i])\n",
        "    plt.title('Segmented Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZL7NA-qf8wWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}